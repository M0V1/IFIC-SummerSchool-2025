{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#install required packages\n",
        "import sys\n",
        "!pip install atlasopenmagic\n",
        "from atlasopenmagic import install_from_environment\n",
        "install_from_environment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThSibgQqkiJs",
        "outputId": "b3294d9c-7b1a-431d-ae4c-5e03e71d05bb"
      },
      "id": "ThSibgQqkiJs",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting atlasopenmagic\n",
            "  Downloading atlasopenmagic-1.0.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from atlasopenmagic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from atlasopenmagic) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->atlasopenmagic) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->atlasopenmagic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->atlasopenmagic) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->atlasopenmagic) (2025.7.9)\n",
            "Downloading atlasopenmagic-1.0.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: atlasopenmagic\n",
            "Successfully installed atlasopenmagic-1.0.1\n",
            "Installing packages: ['aiohttp>=3.9.5', 'atlasopenmagic>=1.0.1', 'awkward>=2.6.7', 'awkward-pandas>=2023.8.0', 'coffea~=0.7.0', 'hist>=2.8.0', 'ipykernel>=6.29.5', 'jupyter>=1.0.0', 'lmfit>=1.3.2', 'matplotlib>=3.9.1', 'metakernel>=0.30.2', 'notebook<7', 'numpy>=1.26.4', 'pandas>=2.2.2', 'papermill>=2.6.0', 'pip>=24.2', 'scikit-learn>=1.5.1', 'uproot>=5.3.10', 'uproot3>=3.14.4', 'fsspec-xrootd>=0.5.1', 'jupyterlab_latex~=3.1.0', 'vector>=1.4.1']\n",
            "Installation complete. You may need to restart your Python environment for changes to take effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uproot # For reading ROOT files efficiently\n",
        "import awkward as ak # To represent nested data in columnar format\n",
        "import pandas as pd # For dataframes, a format widely used in python\n",
        "import numpy as np # For numerical calculations such as histogramming\n",
        "import time # For timing operations and adding delays if needed\n",
        "import matplotlib.pyplot as plt # For creating plots and visualizations\n",
        "from matplotlib.ticker import AutoMinorLocator # for minor ticks\n",
        "import atlasopenmagic as atom  # Provides access to ATLAS Open Data metadata and streaming URLs\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed # Enables parallel execution for faster processing of large datasets\n",
        "# Filter warnings that otherwise appear in output. These are normal in the running of this notebook.\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in sqrt\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"overflow encountered in power\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"overflow encountered in multiply\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in subtract\")\n"
      ],
      "metadata": {
        "id": "2m6q7qfbkjvc"
      },
      "id": "2m6q7qfbkjvc",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Integrated luminosity in inverse picobarns\n",
        "lumi = 36000.\n",
        "\n",
        "# Fraction of events to process\n",
        "fraction = 0.25"
      ],
      "metadata": {
        "id": "dAmg9Ra2kjyF"
      },
      "id": "dAmg9Ra2kjyF",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "atom.set_release('2025e-13tev-beta')\n",
        "\n",
        "mc_defs = {\n",
        "    r'ttbar_Ztt':    {'dids': [410470,700901, 700902],},\n",
        "    r'tautau': {'dids': [346919, 346923, 346927]},\n",
        "    r'Higgs':  {'dids': [345120, 345121, 345122, 345123]},\n",
        "}\n",
        "\n",
        "mc_samples   = atom.build_mc_dataset(mc_defs,   skim='2J2LMET30', protocol='https')\n",
        "data_samples_1 = atom.build_data_dataset('2J2LMET30', name=\"Data\", protocol='https')\n",
        "\n",
        "samples = {**data_samples_1, **mc_samples}\n",
        "\n",
        "variables = [\"mcWeight\", \"ScaleFactor_DiTauTRIGGER\", \"trigE\", \"trigDT\", \"lep_n\", \"lep_pt\",\"ScaleFactor_BTAG\",\"lep_isMediumID\",\n",
        "            \"lep_eta\", \"lep_phi\", \"lep_charge\", \"lep_type\",\"tau_n\",\"tau_pt\", \"tau_e\", \"tau_eta\", \"tau_phi\", \"met\", \"met_phi\", \"sum_of_weights\", \"ScaleFactor_FTAG\",\"lep_isLooseIso\",\n",
        "            \"xsec\", \"jet_pt\", \"jet_btag_quantile\", \"jet_n\", \"jet_eta\", \"jet_phi\", \"jet_e\",\"jet_jvt\",\"lep_isTrigMatched\",\n",
        "            \"lep_type\", \"lep_e\", \"eventNumber\", \"ScaleFactor_ELE\", \"ScaleFactor_TAU\",\"ScaleFactor_PILEUP\",\"filteff\", \"kfac\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eEHG71rkj0d",
        "outputId": "f2fc50d4-5bcc-459e-b6ec-e5d6cd275589"
      },
      "id": "3eEHG71rkj0d",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Active release set to: 2025e-13tev-beta. Metadata cache cleared.\n",
            "\u001b[91mDeprecationWarning: The build_mc_dataset function is deprecated. Use build_dataset with the appropriate MC definitions instead. (/usr/local/lib/python3.11/dist-packages/atlasopenmagic/utils.py:173)\u001b[0m\n",
            "Fetching and caching all metadata for release: 2025e-13tev-beta...\n",
            "Successfully cached 374 datasets.\n",
            "\u001b[91mDeprecationWarning: The build_data_dataset function is deprecated. Use build_dataset with the appropriate data definitions instead. (/usr/local/lib/python3.11/dist-packages/atlasopenmagic/utils.py:161)\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_weight(data):\n",
        "    weight_list =( data[\"ScaleFactor_TAU\"] * data[\"ScaleFactor_DiTauTRIGGER\"] * data[\"ScaleFactor_PILEUP\"] *\n",
        "             ( data[\"ScaleFactor_BTAG\"] * data[\"mcWeight\"] / data[\"sum_of_weights\"]) * (data[\"xsec\"] * data[\"filteff\"] * data[\"kfac\"] * lumi) )\n",
        "    return weight_list"
      ],
      "metadata": {
        "id": "ycR2vPNrkj25"
      },
      "id": "ycR2vPNrkj25",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_trig(trigDT):\n",
        "    return trigDT"
      ],
      "metadata": {
        "id": "MHHe1Ehvkj5H"
      },
      "id": "MHHe1Ehvkj5H",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def two_lep(tau_n):\n",
        "    return tau_n == 2"
      ],
      "metadata": {
        "id": "AbfrqUuqkj7e"
      },
      "id": "AbfrqUuqkj7e",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_lep_pt(tau_pt):\n",
        "    return ak.sum(tau_pt > 20, axis=1) >= 2"
      ],
      "metadata": {
        "id": "z4bKcD1dnHd7"
      },
      "id": "z4bKcD1dnHd7",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_met_et(met_et):\n",
        "    return met_et > 20"
      ],
      "metadata": {
        "id": "Fj6WA9HJnHgj"
      },
      "id": "Fj6WA9HJnHgj",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_charge(charge):\n",
        "    return ak.sum(charge, axis=1) == 0"
      ],
      "metadata": {
        "id": "bBtvLn05nHi0"
      },
      "id": "bBtvLn05nHi0",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_type(type1):\n",
        "    return ak.sum(type1 == 15, axis=1) == 2"
      ],
      "metadata": {
        "id": "7xFgB3TNnHlF"
      },
      "id": "7xFgB3TNnHlF",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_jet(E,pt,b_tag):\n",
        "  E_check = ak.sum(E >= 30 , axis=1) >= 2\n",
        "  pt_check = ak.sum(pt >= 30, axis=1) >= 2\n",
        "  btag_check = ak.sum(b_tag>=3, axis=1) < 1\n",
        "  return (pt_check) & (E_check) & (btag_check)"
      ],
      "metadata": {
        "id": "6KrWCiO8nHnV"
      },
      "id": "6KrWCiO8nHnV",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_DR(eta,phi,eta_M,phi_M):\n",
        "\n",
        "    Dphi1 = np.arccos( np.cos(phi -  phi_M[:,0]) )\n",
        "    Dphi2 = np.arccos( np.cos(phi -  phi_M[:,1]) )\n",
        "\n",
        "    Deta1 = eta - eta_M[:,0]\n",
        "    Deta2 = eta - eta_M[:,1]\n",
        "\n",
        "    DR_M1 = np.sqrt((Deta1)**2 + (Dphi1)**2)\n",
        "    DR_M2 = np.sqrt((Deta2)**2 + (Dphi2)**2)\n",
        "\n",
        "    DR_M1_check = ak.sum(DR_M1 >= 0.4, axis=1) >= 1\n",
        "    DR_M2_check = ak.sum(DR_M2 >= 0.4, axis=1) >= 1\n",
        "\n",
        "    return (DR_M1_check) & (DR_M2_check)"
      ],
      "metadata": {
        "id": "iVvH41CQnHp4"
      },
      "id": "iVvH41CQnHp4",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_VBF(jet_E,pt,eta,phi):\n",
        "    jet_px = pt * np.cos(phi)\n",
        "    jet_py = pt * np.sin(phi)\n",
        "    jet_pz = pt / np.tan(2.0 * np.arctan( np.exp( -eta ) ) )\n",
        "\n",
        "    # Helper function to create combinations of jets\n",
        "    def combo(list_1):\n",
        "        jets_pairs = ak.combinations(list_1, 2, fields=['List1', 'List2'])\n",
        "        sum_List = jets_pairs['List1'] + jets_pairs['List2']\n",
        "        return sum_List\n",
        "\n",
        "    combo_jet_E = combo(jet_E)\n",
        "    combo_jet_px = combo(jet_px)\n",
        "    combo_jet_py = combo(jet_py)\n",
        "    combo_jet_pz = combo(jet_pz)\n",
        "\n",
        "    Mass = np.sqrt(combo_jet_E**2 -(combo_jet_px**2 + combo_jet_py**2 + combo_jet_pz**2))\n",
        "\n",
        "    jets_pairs = ak.combinations(eta, 2, fields=['List1', 'List2'])\n",
        "    abs_dif_eta = np.abs(jets_pairs['List1'] - jets_pairs['List2'])\n",
        "    eta_mult = jets_pairs['List1'] * jets_pairs['List2']\n",
        "\n",
        "    return ak.sum((abs_dif_eta > 3) & (eta_mult < 0) & (Mass>=500), axis=1) > 0"
      ],
      "metadata": {
        "id": "tZJ4tldsnHsU"
      },
      "id": "tZJ4tldsnHsU",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Hmass(E,pt,eta,phi):\n",
        "    tau_E = ak.sum(E, axis=1)\n",
        "    tau_px = ak.sum(pt * np.cos(phi), axis=1)\n",
        "    tau_py = ak.sum(pt * np.sin(phi), axis=1)\n",
        "    tau_pz = ak.sum(pt / np.tan(2.0 * np.arctan( np.exp( -eta ) ) ), axis=1)\n",
        "    Mass = np.sqrt(tau_E**2 -(tau_px**2 + tau_py**2 + tau_pz**2))\n",
        "    return Mass"
      ],
      "metadata": {
        "id": "eBY7eM8qnHuw"
      },
      "id": "eBY7eM8qnHuw",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_file(file_path, sample_name,loop):\n",
        "    # Open the 'analysis' TTree from the ROOT file\n",
        "    tree = uproot.open(file_path + \":analysis\")\n",
        "    sample_data = []\n",
        "\n",
        "    for data in tree.iterate(variables, library=\"ak\", entry_start=int(tree.num_entries * fraction * loop),\n",
        "                             entry_stop=int(tree.num_entries * fraction * (loop+1))):\n",
        "\n",
        "            #data = data[cut_trig(data.trigDT)]\n",
        "            #data = data[Matched_cut(data.lep_isTrigMatched)]\n",
        "            #data = data[two_lep(data.tau_n)]\n",
        "           # data = data[cut_met_et(data.met)]\n",
        "           # data = data[cut_type(data.tau_type)]\n",
        "           # data = data[cut_lep_pt(data.tau_pt)]\n",
        "           # data = data[cut_charge(data.tau_charge)]\n",
        "            #data = data[ID_iso_cut(data.lep_isMediumID, data.lep_isLooseIso)]\n",
        "           # data = data[cut_jet(data.jet_e, data.jet_pt, data.jet_btag_quantile)]\n",
        "           # data = data[cut_DR(data.jet_eta, data.jet_phi, data.tau_eta, data.tau_phi)]\n",
        "           # data = data[cut_VBF(data.jet_e, data.jet_pt, data.jet_eta, data.jet_phi)]\n",
        "\n",
        "\n",
        "            data['Inv_mass'] = Hmass(data.tau_e, data.tau_pt, data.tau_eta, data.tau_phi)\n",
        "\n",
        "            if 'data' not in sample_name:\n",
        "                data['Weight'] = calc_weight(data)\n",
        "            #else:\n",
        "              #  data['Weight'] = ak.ones_like(data['met'])\n",
        "\n",
        "            sample_data.append(data)\n",
        "\n",
        "    # Concatenate all data from the current file into a single array\n",
        "    return ak.concatenate(sample_data, axis=0)"
      ],
      "metadata": {
        "id": "ZJD9Xcl6oPHd"
      },
      "id": "ZJD9Xcl6oPHd",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parallel_analysis(file_path, sample_name):\n",
        "    # Parallel processing\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        # Submit all tasks using a dictionary comprehension\n",
        "        futures = {\n",
        "          executor.submit(process_file, file_path, sample_name, i): i\n",
        "          for i in range(10)\n",
        "        }\n",
        "\n",
        "        results = []\n",
        "        for future in as_completed(futures):\n",
        "            try:\n",
        "                results.append(future.result())\n",
        "            except Exception as e:\n",
        "                print(f\"Error in {sample_name} loop {futures[future]}: {e}\")\n",
        "                continue\n",
        "\n",
        "    # Combine results into an Awkward Array\n",
        "    combined_array = ak.concatenate(results, axis=0) if results else ak.Array([])\n",
        "\n",
        "    return combined_array\n"
      ],
      "metadata": {
        "id": "ol_rESUnoPJ7"
      },
      "id": "ol_rESUnoPJ7",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_all = time.time()  # Define start time\n",
        "data_all = {}  # Dictionary to store results for each sample\n",
        "fraction = 0.2 # Lower this vaule for less running time\n",
        "print(\"The analysis has started\")\n",
        "\n",
        "for s in samples:\n",
        "    frames = []\n",
        "    print(\"processing the \",s,\" samples\")\n",
        "\n",
        "    # Loop over ROOT files associated with the current sample\n",
        "    for val in samples[s]['list']:\n",
        "\n",
        "        DF = parallel_analysis(val, s)\n",
        "        frames.append(DF) # Collect the results\n",
        "\n",
        "    # Store the frames for this sample\n",
        "    data_all[s] = ak.concatenate(frames, axis=0)\n",
        "\n",
        "end_all = time.time()\n",
        "print(f\"\\nTotal time taken to process all samples: {round((end_all - start_all) / 60, 1)} minutes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zijVo512oPMW",
        "outputId": "76bdeacb-af0b-469b-d8ae-2cb69588e6e5"
      },
      "id": "zijVo512oPMW",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analysis has started\n",
            "processing the  Data  samples\n",
            "Error in Data loop 5: reduce() of empty iterable with no initial value\n",
            "Error in Data loop 6: reduce() of empty iterable with no initial value\n",
            "Error in Data loop 7: reduce() of empty iterable with no initial value\n",
            "Error in Data loop 9: reduce() of empty iterable with no initial value\n",
            "Error in Data loop 8: reduce() of empty iterable with no initial value\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Data loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "processing the  ttbar_Ztt  samples\n",
            "Error in ttbar_Ztt loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in ttbar_Ztt loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "processing the  tautau  samples\n",
            "Error in tautau loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in tautau loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "processing the  Higgs  samples\n",
            "Error in Higgs loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 0: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 1: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 2: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 3: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 4: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 5: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 6: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 7: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 8: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "Error in Higgs loop 9: can't pickle multidict._multidict.CIMultiDictProxy objects\n",
            "\n",
            "Total time taken to process all samples: 0.7 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_data(data,fit):\n",
        "\n",
        "    # Define plot parameters\n",
        "    xmin, xmax, step_size = 110, 160, 2\n",
        "\n",
        "    # Define MC data sets and their properties\n",
        "    datasets = [\n",
        "        {'data': data['ttbar_Ztt']['Inv_mass'], 'weights': data['ttbar_Ztt']['Weight'], 'color': 'cyan', 'label': r''},\n",
        "        {'data': data['tautau']['Inv_mass'], 'weights': data['tautau']['Weight'], 'color': 'orange', 'label': r''}]\n",
        "\n",
        "    # Create bin edges and centers\n",
        "    bin_edges = np.arange(xmin, xmax + step_size, step_size)\n",
        "    bin_centres = np.arange(xmin + step_size/2, xmax + step_size/2, step_size)\n",
        "\n",
        "    # Compute the histogram of the data\n",
        "    data_x, _ = np.histogram(data['Data']['Inv_mass'], bins=bin_edges)\n",
        "\n",
        "    data_x_errors = np.sqrt(data_x)  # statistical error on the data\n",
        "\n",
        "    # Create main plot and residual subplot\n",
        "    fig, (main_axes, residual_axes) = plt.subplots(2, 1, figsize=(7, 6), gridspec_kw={'height_ratios': [3, 1]}, sharex=True)\n",
        "\n",
        "    # Plot data with error bars\n",
        "    Cut1 = (bin_centres >= xmin) & (bin_centres <= xmax)  # Cut for main plotting range\n",
        "    main_axes.errorbar(x=bin_centres, y=data_x, yerr=data_x_errors, fmt='ko', label=f'Data entries = {sum(data_x[Cut1])}')\n",
        "\n",
        "    # Plot the Monte Carlo bars\n",
        "    mc_heights = main_axes.hist([d['data'] for d in datasets], bins=bin_edges, weights=[d['weights'] for d in datasets],\n",
        "                                stacked=True,color=[d['color'] for d in datasets], label=[d['label'] for d in datasets])\n",
        "\n",
        "    mc_x_tot = (mc_heights[0][1])  # Stacked background MC y-axis value\n",
        "\n",
        "    # Calculate MC statistical uncertainty: sqrt(sum w^2)\n",
        "    mc_x_err = np.sqrt(np.histogram(np.hstack([d['data'] for d in datasets]), bins=bin_edges,weights=np.hstack([d['weights'] for d in datasets])**2)[0])\n",
        "\n",
        "    # Plot the statistical uncertainty\n",
        "    main_axes.bar(bin_centres, 2*mc_x_err, alpha=0.5, bottom=mc_x_tot-mc_x_err,color='none', hatch=\"////\", width=step_size, label='Stat. Unc.')\n",
        "\n",
        "    # Set up main axes\n",
        "    main_axes.set_xlim(left=xmin, right=xmax)\n",
        "\n",
        "    if fit == True:\n",
        "        higgs_hist, _ = np.histogram(data['Higgs']['Inv_mass'], bins=bin_edges, weights=data['Higgs']['Weight']*100)\n",
        "        main_axes.step(bin_centres, higgs_hist, where='mid', color='purple', linewidth=3, label='Higgs *100')\n",
        "\n",
        "    # Add headspace to the plot\n",
        "    ymax = max(np.max(data_x), np.max(np.sum(mc_heights[0], axis=0)))\n",
        "    main_axes.set_ylim(0, ymax * 1.4)  # Add 40% headspace\n",
        "    main_axes.xaxis.set_minor_locator(AutoMinorLocator())\n",
        "    main_axes.tick_params(which='both', direction='in', top=True, right=True)\n",
        "    main_axes.set_ylabel('Events', y=1, horizontalalignment='right')\n",
        "    main_axes.yaxis.set_minor_locator(AutoMinorLocator())\n",
        "\n",
        "    # Add text to the plot\n",
        "    main_axes.text(0.05, 0.93, 'ATLAS Open Data', transform=main_axes.transAxes, fontsize=13)\n",
        "    main_axes.text(0.05, 0.88, 'for education', transform=main_axes.transAxes, style='italic', fontsize=8)\n",
        "    main_axes.text(0.05, 0.82, r'=13 TeV, 36 fb', transform=main_axes.transAxes)\n",
        "\n",
        "    main_axes.legend(frameon=False)\n",
        "    # Calculate and plot residuals\n",
        "    ratio = data_x / np.sum(mc_heights[0], axis=0)\n",
        "    residual_axes.errorbar(bin_centres, ratio, yerr=abs(ratio*data_x_errors/data_x), fmt='ko')\n",
        "    residual_axes.axhline(1, color='r', linestyle='--')\n",
        "    residual_axes.set_xlabel(r\"tautau\", fontsize=13, x=1, horizontalalignment='right')\n",
        "    residual_axes.set_ylabel('Ratio (Data/MC)')\n",
        "    residual_axes.xaxis.set_minor_locator(AutoMinorLocator())\n",
        "    residual_axes.yaxis.set_minor_locator(AutoMinorLocator())\n",
        "    residual_axes.tick_params(which='both', direction='in', top=True, right=True)\n",
        "    residual_axes.set_ylim(top=3, bottom=0.5)\n",
        "\n",
        "    # Adjust layout\n",
        "    fig.tight_layout()\n",
        "    fig.subplots_adjust(hspace=0.05)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "p11UMFH8oPOr"
      },
      "id": "p11UMFH8oPOr",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Contentdata_all:\", data_all)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou-0cm3nqxuh",
        "outputId": "ebe82118-158d-4d98-b563-30420e205b02"
      },
      "id": "Ou-0cm3nqxuh",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contentdata_all: {'Data': <Array [{mcWeight: 1, ...}, {...}, ..., {...}] type='73473 * {mcWeight: flo...'>, 'ttbar_Ztt': <Array [] type='0 * unknown'>, 'tautau': <Array [] type='0 * unknown'>, 'Higgs': <Array [] type='0 * unknown'>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data(data_all,True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "uIWwSxKJo365",
        "outputId": "dd01caee-a6e0-48a5-8f11-82bf2d0cfa68"
      },
      "id": "uIWwSxKJo365",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'datasets' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-23-506548338.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-21-1554543559.py\u001b[0m in \u001b[0;36mplot_data\u001b[0;34m(data, fit)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Plot the Monte Carlo bars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     mc_heights = main_axes.hist([d['data'] for d in datasets], bins=bin_edges, weights=[d['weights'] for d in datasets],\n\u001b[0m\u001b[1;32m     29\u001b[0m                                 stacked=True,color=[d['color'] for d in datasets], label=[d['label'] for d in datasets])\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d6026ad-09d5-4c53-97fd-cabdd3646084",
      "metadata": {
        "id": "8d6026ad-09d5-4c53-97fd-cabdd3646084"
      },
      "outputs": [],
      "source": [
        "!rm -rf IFIC-SummerSchool-2025\n",
        "!git clone https://github.com/M0V1/IFIC-SummerSchool-2025.git\n",
        "!pip install  numpy pandas uproot matplotlib mplhep awkward"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls IFIC-SummerSchool-2025\n",
        "!find IFIC-SummerSchool-2025 -name \"*.root\""
      ],
      "metadata": {
        "id": "7CQWQWwMPtvJ"
      },
      "id": "7CQWQWwMPtvJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uproot\n",
        "import awkward as ak\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import AutoMinorLocator\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "import time\n",
        "\n",
        "# Integrated luminosity in inverse picobarns\n",
        "lumi = 36000."
      ],
      "metadata": {
        "id": "5a-gEr-IFwEh"
      },
      "id": "5a-gEr-IFwEh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [\n",
        "    \"IFIC-SummerSchool-2025/ODEO_FEB2025_v0_2J2LMET30_mc_700903.Sh_2214_Ztt_maxHTpTV2_Mll10_40_CVetoBVeto.2J2LMET30.root\",   #bkg\n",
        "    \"IFIC-SummerSchool-2025/ODEO_FEB2025_v0_2J2LMET30_mc_410471.PhPy8EG_A14_ttbar_hdamp258p75_allhad.2J2LMET30.root\",     #bkg\n",
        "    \"IFIC-SummerSchool-2025/ODEO_FEB2025_v0_2J2LMET30_mc_345121.PowhegPy8EG_NNLOPS_nnlo_30_ggH125_tautaulm15hp20.2J2LMET30.root\", #signal\n",
        "    \"IFIC-SummerSchool-2025/ODEO_FEB2025_v0_2J2LMET30_mc_345122.PowhegPy8EG_NNLOPS_nnlo_30_ggH125_tautaulp15hm20.2J2LMET30.root\",#signal\n",
        "    \"IFIC-SummerSchool-2025/ODEO_FEB2025_v0_2J2LMET30_mc_346343.PhPy8EG_A14NNPDF23_NNPDF30ME_ttH125_allhad.2J2LMET30.root\",\n",
        "    \"IFIC-SummerSchool-2025/ODEO_FEB2025_v0_2J2LMET30_mc_700792.Sh_2214_Ztautau_maxHTpTV2_BFilter.2J2LMET30.root\",     #bkg\n",
        "    \"IFIC-SummerSchool-2025/ODEO_FEB2025_v0_2J2LMET30_data15_periodF.2J2LMET30.root\",  #data\n",
        "    \"IFIC-SummerSchool-2025/ODEO_FEB2025_v0_2J2LMET30_mc_346344.PhPy8EG_A14NNPDF23_NNPDF30ME_ttH125_semilep.2J2LMET30.root\", #signal\n",
        "    \"IFIC-SummerSchool-2025/ODEO_FEB2025_v0_2J2LMET30_data15_periodD.2J2LMET30.root\",  #data\n",
        "    \"IFIC-SummerSchool-2025/ODEO_FEB2025_v0_2J2LMET30_data15_periodH.2J2LMET30.root\",  #data\n",
        "    \"IFIC-SummerSchool-2025/ODEO_FEB2025_v0_2J2LMET30_mc_700902.Sh_2214_Ztt_maxHTpTV2_Mll10_40_CFilterBVeto.2J2LMET30.root\", #bkg\n",
        "    \"IFIC-SummerSchool-2025/ODEO_FEB2025_v0_2J2LMET30_mc_345120.PowhegPy8EG_NNLOPS_nnlo_30_ggH125_tautaul13l7.2J2LMET30.root\",\n",
        "    \"IFIC-SummerSchool-2025/ODEO_FEB2025_v0_2J2LMET30_mc_700901.Sh_2214_Ztt_maxHTpTV2_Mll10_40_BFilter.2J2LMET30.root\" #bkg\n",
        "]\n",
        "\n",
        "tree_name = \"analysis\"\n"
      ],
      "metadata": {
        "id": "voT6Zuo3FwHp"
      },
      "id": "voT6Zuo3FwHp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_weight(data):\n",
        "    weight_list = (data[\"ScaleFactor_TAU\"] * data[\"ScaleFactor_DiTauTRIGGER\"] * data[\"ScaleFactor_PILEUP\"] *\n",
        "                   (data[\"ScaleFactor_BTAG\"] * data[\"mcWeight\"] / data[\"sum_of_weights\"]) *\n",
        "                   (data[\"xsec\"] * data[\"filteff\"] * data[\"kfac\"] * lumi))\n",
        "    return weight_list"
      ],
      "metadata": {
        "id": "ArchEXfgFwKk"
      },
      "id": "ArchEXfgFwKk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_trig(trigDT):\n",
        "    return trigDT\n",
        "\n",
        "def cut_met_et(met_et):\n",
        "    return met_et > 20\n",
        "\n",
        "def cut_leading_jet(jet_pt):\n",
        "    return ak.sum(jet_pt > 40, axis=1) >= 1\n",
        "def cut_tau_pt(tau_pt):\n",
        "    return ak.sum(tau_pt > 5, axis=1) >= 2"
      ],
      "metadata": {
        "id": "8OIgdGHwFwLw"
      },
      "id": "8OIgdGHwFwLw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Hmass(E, pt, eta, phi):\n",
        "    tau_E = ak.sum(E, axis=1)\n",
        "    tau_px = ak.sum(pt * np.cos(phi), axis=1)\n",
        "    tau_py = ak.sum(pt * np.sin(phi), axis=1)\n",
        "    tau_pz = ak.sum(pt * np.tanh(eta), axis=1)\n",
        "    Mass = np.sqrt(tau_E**2 - (tau_px**2 + tau_py**2 + tau_pz**2))\n",
        "    return Mass\n"
      ],
      "metadata": {
        "id": "ZxOs3HyrFwOL"
      },
      "id": "ZxOs3HyrFwOL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_file(file_path, tree_name, loop):\n",
        "    tree = uproot.open(f\"{file_path}:{tree_name}\")\n",
        "    sample_data = []\n",
        "\n",
        "    variables = [\"tau_pt\", \"tau_eta\", \"tau_phi\", \"tau_e\", \"tau_charge\", \"trigT\", \"lep_isTrigMatched\", \"tau_n\", \"met\", \"lep_type\", \"lep_isMediumID\", \"lep_isLooseIso\", \"jet_e\", \"jet_pt\", \"jet_eta\", \"jet_phi\", \"jet_btag_quantile\", \"ScaleFactor_TAU\", \"ScaleFactor_DiTauTRIGGER\", \"ScaleFactor_PILEUP\", \"ScaleFactor_BTAG\", \"mcWeight\", \"sum_of_weights\", \"xsec\", \"filteff\", \"kfac\"]\n",
        "\n",
        "    for data in tree.iterate(variables, library=\"ak\", entry_start=int(tree.num_entries * fraction * loop), entry_stop=int(tree.num_entries * fraction * (loop + 1))):\n",
        "        data = data[cut_tau_pt(data.tau_pt)]\n",
        "        data = data[cut_leading_jet(data.jet_pt)]\n",
        "       # data = data[cut_trig(data.trigT)]\n",
        "        data = data[cut_met_et(data.met)]\n",
        "        data['Inv_mass'] = Hmass(data.tau_e, data.tau_pt, data.tau_eta, data.tau_phi)\n",
        "        data['Weight'] = calc_weight(data)\n",
        "        sample_data.append(data)\n",
        "\n",
        "    return ak.concatenate(sample_data, axis=0)\n"
      ],
      "metadata": {
        "id": "oTNAWxi0FwUa"
      },
      "id": "oTNAWxi0FwUa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parallel_analysis(file_list, tree_name):\n",
        "    combined_data = []\n",
        "    for file_path in file_list:\n",
        "        with ProcessPoolExecutor() as executor:\n",
        "            futures = {executor.submit(process_file, file_path, tree_name, i): i for i in range(10)}\n",
        "            results = []\n",
        "            for future in as_completed(futures):\n",
        "                try:\n",
        "                    results.append(future.result())\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in file {file_path}, loop {futures[future]}: {e}\")\n",
        "        if results:\n",
        "            combined_data.append(ak.concatenate(results, axis=0))\n",
        "\n",
        "    return ak.concatenate(combined_data, axis=0) if combined_data else ak.Array([])\n"
      ],
      "metadata": {
        "id": "Ola47TvWFwW7"
      },
      "id": "Ola47TvWFwW7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main analysis loop\n",
        "start_all = time.time()\n",
        "fraction = 1\n",
        "print(\"The analysis has started\")\n",
        "\n",
        "bkg_files = [\n",
        "    files[0],  # Ztt_maxHTpTV2_Mll10_40_CVetoBVeto\n",
        "    files[1],  # ttbar_allhad\n",
        "    files[5],  # Ztautau_maxHTpTV2_BFilter\n",
        "    files[10], # Ztt_maxHTpTV2_CFilterBVeto\n",
        "    files[12]  # Ztt_maxHTpTV2_BFilter\n",
        "]\n",
        "\n",
        "signal_files = [\n",
        "    files[2],  # ggH125_tautaulm15hp20\n",
        "    files[3],  # ggH125_tautaulp15hm20\n",
        "    files[11], # ggH125_tautaul13l7\n",
        "    files[4],  # ttH125_allhad\n",
        "    files[7],  # ttH125_semilep\n",
        "]\n",
        "\n",
        "data_files = [\n",
        "   # files[6],  # data15_periodF\n",
        "   # files[8],  # data15_periodD\n",
        "    files[9],  # data15_periodH\n",
        "]\n",
        "\n",
        "bkg_data = parallel_analysis(bkg_files, tree_name)\n",
        "signal_data = parallel_analysis(signal_files, tree_name)\n",
        "data_data = parallel_analysis(data_files, tree_name)\n"
      ],
      "metadata": {
        "id": "X-HWzHQmFwZL"
      },
      "id": "X-HWzHQmFwZL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_data(bkg, signal, data, fit=True):\n",
        "    xmin, xmax, step_size = 110, 160, 2\n",
        "    bin_edges = np.arange(xmin, xmax + step_size, step_size)\n",
        "    bin_centres = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
        "\n",
        "\n",
        "    data_y, _ = np.histogram(data['Inv_mass'], bins=bin_edges)\n",
        "    data_yerr = np.sqrt(data_y)\n",
        "\n",
        "\n",
        "    bkg_y, _ = np.histogram(bkg['Inv_mass'], bins=bin_edges, weights=bkg['Weight'])\n",
        "    signal_y, _ = np.histogram(signal['Inv_mass'], bins=bin_edges, weights=signal['Weight'])\n",
        "\n",
        "\n",
        "    stacked_mc = np.vstack([bkg_y, signal_y])\n",
        "    total_mc = np.sum(stacked_mc, axis=0)\n",
        "\n",
        "\n",
        "    total_mc_err = np.sqrt(\n",
        "        np.histogram(bkg['Inv_mass'], bins=bin_edges, weights=bkg['Weight']**2)[0] +\n",
        "        np.histogram(signal['Inv_mass'], bins=bin_edges, weights=signal['Weight']**2)[0]\n",
        "    )\n",
        "\n",
        "    fig, (main_ax, ratio_ax) = plt.subplots(2, 1, figsize=(7, 6), gridspec_kw={'height_ratios': [3, 1]}, sharex=True)\n",
        "\n",
        "    main_ax.errorbar(bin_centres, data_y, yerr=data_yerr, fmt='ko', label=f'Data ({sum(data_y)} entries)')\n",
        "\n",
        "\n",
        "    main_ax.hist([bkg['Inv_mass'], signal['Inv_mass']],\n",
        "                 bins=bin_edges,\n",
        "                 weights=[bkg['Weight'], signal['Weight']],\n",
        "                 stacked=True,\n",
        "                 color=['cyan', 'red'],\n",
        "                 label=[r'$Bkg$', r'$Signal$'])\n",
        "\n",
        "\n",
        "    main_ax.bar(bin_centres, 2 * total_mc_err, alpha=0.5, bottom=total_mc - total_mc_err,\n",
        "                color='none', hatch=\"////\", width=step_size, label='Stat. unc.')\n",
        "\n",
        "    main_ax.set_xlim(xmin, xmax)\n",
        "    main_ax.set_ylim(0, max(max(data_y), max(total_mc)) * 1.5)\n",
        "    main_ax.set_ylabel(\"Events\")\n",
        "    main_ax.text(0.05, 0.93, 'ATLAS Open Data', transform=main_ax.transAxes, fontsize=13)\n",
        "    main_ax.text(0.05, 0.88, 'for education', transform=main_ax.transAxes, style='italic', fontsize=8)\n",
        "    main_ax.text(0.05, 0.82, r'$\\sqrt{s}=13$ TeV, 36 fb$^{-1}$', transform=main_ax.transAxes)\n",
        "    main_ax.legend(frameon=False)\n",
        "\n",
        "\n",
        "    ratio = data_y / total_mc\n",
        "    ratio_err = ratio * np.sqrt((data_yerr / data_y)**2 + (total_mc_err / total_mc)**2)\n",
        "    ratio_ax.errorbar(bin_centres, ratio, yerr=ratio_err, fmt='ko')\n",
        "    ratio_ax.axhline(1, color='red', linestyle='--')\n",
        "    ratio_ax.set_ylabel(\"Data / MC\")\n",
        "    ratio_ax.set_ylim(0.5, 1.5)\n",
        "    ratio_ax.set_xlabel(r\"$m_{\\tau\\tau}$ [GeV]\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(hspace=0.05)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_data(bkg_data, signal_data, data_data)\n"
      ],
      "metadata": {
        "id": "wSNAK4vmQqC9"
      },
      "id": "wSNAK4vmQqC9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import AutoMinorLocator\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "# Gaussian\n",
        "def gaussian(x, A, mu, sigma):\n",
        "    return A * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
        "\n",
        "#polynomial\n",
        "def poly2(x, a, b, c):\n",
        "    return a * x**2 + b * x + c\n",
        "\n",
        "def poly3(x, a, b, c, d):\n",
        "    return a * x**3 + b * x**2 + c * x + d\n",
        "\n",
        "def plot_data(bkg, signal, data, fit=True):\n",
        "    xmin, xmax, step_size = 110, 160, 2\n",
        "    bin_edges = np.arange(xmin, xmax + step_size, step_size)\n",
        "    bin_centres = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
        "\n",
        "    data_y, _ = np.histogram(data['Inv_mass'], bins=bin_edges)\n",
        "    data_yerr = np.sqrt(data_y)\n",
        "\n",
        "    bkg_y, _ = np.histogram(bkg['Inv_mass'], bins=bin_edges, weights=bkg['Weight'])\n",
        "    signal_y, _ = np.histogram(signal['Inv_mass'], bins=bin_edges, weights=signal['Weight'])\n",
        "\n",
        "    stacked_mc = np.vstack([bkg_y, signal_y])\n",
        "    total_mc = np.sum(stacked_mc, axis=0)\n",
        "\n",
        "    total_mc_err = np.sqrt(\n",
        "        np.histogram(bkg['Inv_mass'], bins=bin_edges, weights=bkg['Weight']**2)[0] +\n",
        "        np.histogram(signal['Inv_mass'], bins=bin_edges, weights=signal['Weight']**2)[0]\n",
        "    )\n",
        "\n",
        "    fig, (main_ax, ratio_ax) = plt.subplots(2, 1, figsize=(7, 6), gridspec_kw={'height_ratios': [3, 1]}, sharex=True)\n",
        "    main_ax.errorbar(bin_centres, data_y, yerr=data_yerr, fmt='ko', label=f'Data ({sum(data_y)} entries)')\n",
        "\n",
        "\n",
        "    main_ax.hist([bkg['Inv_mass'], signal['Inv_mass']],\n",
        "                 bins=bin_edges,\n",
        "                 weights=[bkg['Weight'], signal['Weight']],\n",
        "                 stacked=True,\n",
        "                 color=['cyan', 'red'],\n",
        "                 label=[r'$Bkg$', r'$Signal$'])\n",
        "\n",
        "   #stat error\n",
        "    main_ax.bar(bin_centres, 2 * total_mc_err, alpha=0.5, bottom=total_mc - total_mc_err,\n",
        "                color='none', hatch=\"////\", width=step_size, label='Stat. unc.')\n",
        "\n",
        "    # Fit\n",
        "    if fit:\n",
        "        mask = data_y > 0\n",
        "        try:\n",
        "            popt, pcov = curve_fit(gaussian, bin_centres[mask], data_y[mask], p0=[max(data_y), 125, 10], sigma=data_yerr[mask])\n",
        "            fit_curve = gaussian(bin_centres, *popt)\n",
        "            main_ax.plot(bin_centres, fit_curve, 'm--', linewidth=2, label=f'Gaussian Fit\\n$\\mu$={popt[1]:.1f}, $\\sigma$={popt[2]:.1f}')\n",
        "        except RuntimeError:\n",
        "            print(\"Fit failed: could not converge.\")\n",
        "\n",
        "        try:\n",
        "            popt_poly, pcov_poly = curve_fit(poly2, bin_centres[mask], data_y[mask], sigma=data_yerr[mask])\n",
        "            fit_poly_curve = poly2(bin_centres, *popt_poly)\n",
        "            main_ax.plot(bin_centres, fit_poly_curve, 'g--', linewidth=2, label=f'Poly3 Fit')\n",
        "        except RuntimeError:\n",
        "            print(\"Polynomial fit failed.\")\n",
        "\n",
        "    main_ax.set_xlim(xmin, xmax)\n",
        "    main_ax.set_ylim(0, max(max(data_y), max(total_mc)) * 1.5)\n",
        "    main_ax.set_ylabel(\"Events\")\n",
        "    main_ax.text(0.05, 0.93, 'ATLAS Open Data', transform=main_ax.transAxes, fontsize=13)\n",
        "    main_ax.text(0.05, 0.88, 'for education', transform=main_ax.transAxes, style='italic', fontsize=8)\n",
        "    main_ax.text(0.05, 0.82, r'$\\sqrt{s}=13$ TeV, 36 fb$^{-1}$', transform=main_ax.transAxes)\n",
        "    main_ax.legend(frameon=False)\n",
        "\n",
        "    ratio = data_y / total_mc\n",
        "    ratio_err = ratio * np.sqrt((data_yerr / data_y)**2 + (total_mc_err / total_mc)**2)\n",
        "    ratio_ax.errorbar(bin_centres, ratio, yerr=ratio_err, fmt='ko')\n",
        "    ratio_ax.axhline(1, color='red', linestyle='--')\n",
        "    ratio_ax.set_ylabel(\"Data / MC\")\n",
        "    ratio_ax.set_ylim(0.5, 3.5)\n",
        "    ratio_ax.set_xlabel(r\"$m_{\\tau\\tau}$ [GeV]\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(hspace=0.05)\n",
        "    plt.show()\n",
        "\n",
        "plot_data(bkg_data, signal_data, data_data)"
      ],
      "metadata": {
        "id": "J2y9c_JZWPAr"
      },
      "id": "J2y9c_JZWPAr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0es3rVr1akO7"
      },
      "id": "0es3rVr1akO7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}